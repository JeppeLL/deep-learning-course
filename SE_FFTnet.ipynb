{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SE_FFTnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeppeLL/deep-learning-course/blob/master/SE_FFTnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59RDnUMjDw21",
        "colab_type": "code",
        "outputId": "1144aea8-39ed-4134-f90b-f7906e47384f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!pip install torchaudio\n",
        "!pip install pystoi\n",
        "!pip install https://github.com/ludlows/python-pesq/archive/master.zip\n",
        "import numpy as np\n",
        "import glob\n",
        "import librosa\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import Audio\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "#import torch.optim as optim\n",
        "import torchaudio as ta\n",
        "if torch.cuda.is_available():\n",
        "  cuda=True\n",
        "else:\n",
        "  cuda=False\n",
        "#import datetime as dt\n",
        "import os\n",
        "from torch.autograd import Variable\n",
        "from IPython.display import Image, display, clear_output\n",
        "import datetime\n",
        "from pystoi.stoi import stoi\n",
        "from pesq import pesq\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: torch==1.3.0 in /usr/local/lib/python3.6/dist-packages (from torchaudio) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.3.0->torchaudio) (1.17.4)\n",
            "Requirement already satisfied: pystoi in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pystoi) (1.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pystoi) (1.17.4)\n",
            "Collecting https://github.com/ludlows/python-pesq/archive/master.zip\n",
            "\u001b[?25l  Downloading https://github.com/ludlows/python-pesq/archive/master.zip\n",
            "\u001b[K     | 399kB 268kB/s\n",
            "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): pesq==0.0.1 from https://github.com/ludlows/python-pesq/archive/master.zip in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: pesq\n",
            "  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pesq: filename=pesq-0.0.1-cp36-cp36m-linux_x86_64.whl size=162016 sha256=0b661fd7a3918c174fd47f565cda73af0f8325c587791ae897782f4a633ff633\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2nd1anyj/wheels/85/91/09/5ae7677a054a05d49111dc8f3b282e886b3852348384893a32\n",
            "Successfully built pesq\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzT_zphwD2sg",
        "colab_type": "text"
      },
      "source": [
        "# DataLoader class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9zHvc4JD3OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_filepaths(data_directory, dataset):\n",
        "    \"\"\"\n",
        "    Returns a list of file paths for the specified dataset.\n",
        "    \"\"\"\n",
        "    assert dataset in {'clean-speech', 'noise', 'impulse-responses'}\n",
        "    \n",
        "    regex = '/'.join((data_directory, dataset, '*.wav'))\n",
        "    filepaths = glob.glob(regex)\n",
        "    \n",
        "    if len(filepaths) == 0:\n",
        "        raise Exception('No files were found in the specified dataset!')\n",
        "    \n",
        "    return filepaths\n",
        "\n",
        "class DataLoader():\n",
        "  def __init__(self, data_directory='/content/drive/My Drive/reverberation'\n",
        "               , sample_rate=16000\n",
        "               ,GT_range=[0,3121], IR_range=[0,27], N_range=[0,15]\n",
        "               ,sequence_length_GT=32000, sequence_length_IR=16000):\n",
        "    \n",
        "    self.sample_rate=sample_rate\n",
        "    self.seq_len_GT=sequence_length_GT\n",
        "    self.seq_len_IR=sequence_length_IR\n",
        "    self.marc=None\n",
        "    self.GT_is_padded = False\n",
        "\n",
        "    if GT_range:\n",
        "      self.paths_GT=get_filepaths(data_directory, 'clean-speech')[GT_range[0]:GT_range[1]]\n",
        "    else:\n",
        "      self.paths_GT=None\n",
        "    if IR_range:\n",
        "      self.paths_IR=get_filepaths(data_directory, 'impulse-responses')[IR_range[0]:IR_range[1]]\n",
        "    else:\n",
        "      self.paths_IR=None\n",
        "    if N_range:\n",
        "      self.paths_N=get_filepaths(data_directory, 'noise')[N_range[0]:N_range[1]]\n",
        "    else:\n",
        "      self.paths_N=None\n",
        "    print(f\"Found {len(self.paths_GT)} ground truth files in data set\")\n",
        "    print(f\"Found {len(self.paths_IR)} impulse response files in data set\")\n",
        "    print(f\"Found {len(self.paths_N)} noise files in data set\\n\")\n",
        "\n",
        "\n",
        "    self.use_cuda = torch.cuda.is_available()\n",
        "    print(\"Running GPU.\") if self.use_cuda else print(\"No GPU available.\")\n",
        "\n",
        "    ###Load and normalize\n",
        "    self.GT=list()\n",
        "    self.IR=list()\n",
        "    self.N=list()\n",
        "    \n",
        "    self.GT_lengths=list()\n",
        "    self.IR_lengths=list()\n",
        "    self.N_lengths=list()\n",
        "\n",
        "    self.GT_filenames=list()\n",
        "    self.IR_filenames=list()\n",
        "    self.N_filenames=list()\n",
        "    \n",
        "    #lengths=list()\n",
        "    #filenames=list()\n",
        "    #maxcount=len(path)\n",
        "\n",
        "    if GT_range:\n",
        "      print(\"GT\")\n",
        "      count=0\n",
        "      maxcount=GT_range[1]-GT_range[0]\n",
        "      for file in self.paths_GT:\n",
        "        count+=1\n",
        "        if count % 100 == 1:\n",
        "          print(f\"Processing file {count} of {maxcount}...\")\n",
        "        \n",
        "        ##Load the file into memory\n",
        "        d = self.load(file)\n",
        "\n",
        "        #Add to class memory:\n",
        "        self.GT.append(d)\n",
        "        self.GT_lengths.append(d.shape[1])\n",
        "        self.GT_filenames.append(file)\n",
        "\n",
        "    if IR_range:\n",
        "      print(\"IR\")\n",
        "      count=0\n",
        "      maxcount=IR_range[1]-IR_range[0]\n",
        "      for file in self.paths_IR:\n",
        "        count+=1\n",
        "        if count % 100 == 1:\n",
        "          print(f\"Processing file {count} of {maxcount}...\")\n",
        "        \n",
        "        ##Load the file into memory\n",
        "        d = self.load(file)\n",
        "\n",
        "        #Add to class memory:\n",
        "        self.IR.append(d)\n",
        "        self.IR_lengths.append(d.shape[1])\n",
        "        self.IR_filenames.append(file)\n",
        "\n",
        "\n",
        "    if N_range:\n",
        "      print(\"N\")\n",
        "      count=0\n",
        "      maxcount=N_range[1]-N_range[0]\n",
        "      for file in self.paths_N:\n",
        "        count+=1\n",
        "        if count % 100 == 1:\n",
        "          print(f\"Processing file {count} of {maxcount}...\")\n",
        "        \n",
        "        ##Load the file into memory\n",
        "        d = self.load(file)\n",
        "\n",
        "        #Add to class memory:\n",
        "        self.N.append(d)\n",
        "        self.N_lengths.append(d.shape[1])\n",
        "        self.N_filenames.append(file)\n",
        "  \n",
        "\n",
        "\n",
        "  def load(self, file):\n",
        "    ##Load the file into memory\n",
        "    if self.use_cuda:\n",
        "      d, sr = ta.load(file)\n",
        "      #sr = sr.cuda()\n",
        "      if d.shape[0]>1:\n",
        "        d=d[0,:].unsqueeze(0)\n",
        "      \n",
        "      #print(d.shape)\n",
        "      #print()\n",
        "      if sr!=self.sample_rate:\n",
        "        #print(\"Sample rates not equal\")\n",
        "        d = ta.transforms.Resample(sr, self.sample_rate)(d)\n",
        "      #d = d.squeeze(0)\n",
        "      d  = d.cuda()\n",
        "\n",
        "    else:    \n",
        "      d, sr = librosa.load(file, sr=self.sample_rate)\n",
        "      #normalize\n",
        "      d_minus_mean=d-np.mean(d)\n",
        "      d = d_minus_mean/np.max(np.abs(d_minus_mean))\n",
        "    return d\n",
        "  \n",
        "  def cropAndPadIR(self,matrix_ops=True):\n",
        "    #IR=self.IR\n",
        "    for i in range(len(self.IR)):\n",
        "      idx = torch.argmax(torch.abs(self.IR[i]))\n",
        "      self.IR[i]=self.IR[i][:,idx:]\n",
        "      self.IR[i]=torch.cat((self.IR[i][:,:self.seq_len_IR],\n",
        "                            torch.zeros(1,max(0,self.seq_len_IR-self.IR[i].shape[1])).cuda()),dim=1)\n",
        "    if matrix_ops:\n",
        "      self.IR=torch.stack(self.IR)\n",
        "      \n",
        "  \n",
        "  def cropAndPadGT(self,matrix_ops=True):\n",
        "    #for gt in self.GT:\n",
        "    #  gt=torch.cat((gt[:,:self.seq_len_GT],torch.zeros(1,max(0,self.seq_len_GT-gt.shape[1])).cuda()),dim=1) \n",
        "    for i in range(len(self.GT)):\n",
        "      self.GT[i]=torch.cat((self.GT[i][:,:self.seq_len_GT],\n",
        "                            torch.zeros(1,max(0,self.seq_len_GT-self.GT[i].shape[1])).cuda()),dim=1) \n",
        "    self.GT_is_padded=True\n",
        "    if matrix_ops:\n",
        "      self.GT=torch.stack(self.GT)\n",
        "    \n",
        "  def add_reverb(self,matrix_ops=True):\n",
        "    ## Takes the ground truth (GT_files), and applies convolutions from IR_files ##\n",
        "    ## GT_lengths is the amount of samples in each ground truth files ##\n",
        "    ## IR_lengths is the amount of samples in each impulse response files ##\n",
        "    if self.GT_is_padded: \n",
        "      if self.use_cuda:\n",
        "        if matrix_ops:\n",
        "          self.GT_IR = torch.nn.functional.conv1d(self.GT,torch.flip(self.IR,[2]),padding=self.IR.shape[2])[:,:,1:-self.IR.shape[2]]\n",
        "          self.GT_IR = self.GT_IR.contiguous()\n",
        "        else:\n",
        "          self.GT_IR = []\n",
        "          len_GT = len(self.GT)\n",
        "          for gt in range(len_GT):\n",
        "            if gt % 100 == 1:\n",
        "              print(f\"Adding reverb to GT {gt} of {len_GT}...\")\n",
        "            for ir in range(len(self.IR)):\n",
        "              gt_ir = torch.nn.functional.conv1d(self.GT[gt].unsqueeze(0),torch.flip(self.IR[ir].unsqueeze(0),[2]),padding=self.IR[ir].shape[1])[:,:,1:-self.IR[ir].shape[1]]\n",
        "              self.GT_IR.append(gt_ir)\n",
        "          print(\"stacking GT_IR\")\n",
        "          self.GT_IR = torch.stack(self.GT_IR) \n",
        "          print(\"stacking GT\")\n",
        "          self.GT = torch.stack(self.GT)\n",
        "          print(\"stacking IR\")\n",
        "          self.IR = torch.stack(self.IR)\n",
        "\n",
        "    else:\n",
        "      print(\"ERROR: you should pad GT first\")\n",
        "  \n",
        "\n",
        "  def normalize(self):\n",
        "    max_abs = torch.max(torch.abs(self.GT_IR),2)[0]\n",
        "    max_abs = max_abs.unsqueeze(2) #Need to be shape (GT,IR,1)\n",
        "    eps = 1e-12\n",
        "    self.GT_IR = self.GT_IR / (max_abs + eps)\n",
        "\n",
        "  def cpu(self):\n",
        "    self.IR=self.IR.cpu()\n",
        "    self.GT=self.GT.cpu()\n",
        "    self.GT_IR=self.GT_IR.cpu()\n",
        "\n",
        "  def spectrogram(self,n_fft=160, melScale=False):\n",
        "    ##Turns raw audio signal into a Spectrogram. Either on the Hz-scale or Mel-scale.\n",
        "    ##Also converts to logarithmic scale.\n",
        "    if melScale:\n",
        "      spect = ta.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=n_fft)\n",
        "    else:\n",
        "      spect = ta.transforms.Spectrogram(n_fft=n_fft)\n",
        "    #self.GT_spectrogram=spect(self.GT.squeeze(1))[:,:,:-1].log2()\n",
        "    #self.GT_IR_spectrogram=spect(self.GT_IR.view(-1,1,self.GT_IR.shape[2]).squeeze(1))[:,:,:-1].log2()\n",
        "    self.GT_spectrogram=spect(self.GT.squeeze(1))\n",
        "    self.GT_IR_spectrogram=spect(self.GT_IR.view(-1,1,self.GT_IR.shape[2]).squeeze(1))\n",
        "      \n",
        "  def stft(self, n_fft=160):\n",
        "    self.GT_stft = torch.stft(self.GT.squeeze(1), n_fft, hop_length=n_fft//2)\n",
        "    self.GT_IR_stft = torch.stft(self.GT_IR.view(-1,1,self.GT_IR.shape[2]).squeeze(1), n_fft, hop_length=n_fft//2)\n",
        "    #print(f\"GT_stft.shape: {self.GT_stft.shape}\")\n",
        "    #print(f\"GT_IR_stft.shape: {self.GT_IR_stft.shape}\")\n",
        "    self.GT_mag,self.GT_phase = ta.functional.magphase(self.GT_stft)\n",
        "    self.GT_IR_mag,self.GT_IR_phase = ta.functional.magphase(self.GT_IR_stft)\n",
        "    #print(f\"GT_mag.shape: {self.GT_mag.shape}\")\n",
        "    #print(f\"GT_IR_mag.shape: {self.GT_IR_mag.shape}\")\n",
        "    #print(f\"GT_phase.shape: {self.GT_phase.shape}\")\n",
        "    #print(f\"GT_IR_phase.shape: {self.GT_IR_phase.shape}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSakon_kEFMo",
        "colab_type": "text"
      },
      "source": [
        "# Iterator class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdEH00eqEHL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Iterator():\n",
        "  def __init__(self, object, mode='waveform'):\n",
        "    self.paths_GT = object.paths_GT\n",
        "    self.paths_IR = object.paths_IR\n",
        "    self.mode=mode\n",
        "    if self.mode=='spectrogram':\n",
        "      self.GT = object.GT_spectrogram.repeat_interleave(len(self.paths_IR),dim=0).unsqueeze(1)\n",
        "      self.GT_IR = object.GT_IR_spectrogram.unsqueeze(1)\n",
        "    elif self.mode == 'FFTnet':\n",
        "      self.GT = object.GT.repeat_interleave(len(self.paths_IR),dim=0)\n",
        "      self.GT_IR = object.GT_IR\n",
        "    elif self.mode=='waveform':\n",
        "      self.GT = object.GT.repeat_interleave(len(self.paths_IR),dim=0)\n",
        "      self.GT_IR = object.GT_IR\n",
        "    elif self.mode=='stft':\n",
        "      self.GT = object.GT_mag.repeat_interleave(len(self.paths_IR),dim=0).unsqueeze(1)\n",
        "      self.GT_IR = object.GT_IR_mag.unsqueeze(1)\n",
        "      self.GT_phase = object.GT_phase.repeat_interleave(len(self.paths_IR),dim=0).unsqueeze(1)\n",
        "      self.GT_IR_phase = object.GT_IR_phase.unsqueeze(1)\n",
        "\n",
        "  def setChunkSize(self,k):\n",
        "    self.chunkSize=k\n",
        "  def setBatchSize(self,k):\n",
        "    self.batchSize=k\n",
        "\n",
        "  def chunkify(self):\n",
        "    if self.mode=='spectrogram':\n",
        "      self.GT_IR = self.GT_IR.view(-1,1,self.GT_IR.shape[2],self.chunkSize)\n",
        "      self.GT = self.GT.view(-1,1,self.GT_IR.shape[2],self.chunkSize)\n",
        "    elif self.mode=='FFTnet':\n",
        "      pass\n",
        "      # self.GT_IR = self.GT_IR.view(-1,1,self.GT_IR.shape[2],self.chunkSize)\n",
        "      self.GT = self.GT.view(-1,self.GT_IR.shape[1],self.GT_IR.shape[2])\n",
        "    elif self.mode=='waveform':\n",
        "      self.GT_IR = self.GT_IR.view(-1,1,self.chunkSize)\n",
        "      self.GT = self.GT.view(-1,1,self.chunkSize)\n",
        "    elif self.mode=='stft':\n",
        "      self.GT_IR = self.GT_IR.view(-1,1,self.GT_IR.shape[2],self.chunkSize)\n",
        "      self.GT = self.GT.view(-1,1,self.GT_IR.shape[2],self.chunkSize)\n",
        "      self.GT_IR_phase = self.GT_IR_phase.view(-1,1,self.GT_IR_phase.shape[2],self.chunkSize)\n",
        "      self.GT_phase = self.GT_phase.view(-1,1,self.GT_IR_phase.shape[2],self.chunkSize)\n",
        "  \n",
        "  def __iter__(self):\n",
        "    self.n=0\n",
        "    return self\n",
        "  def __next__(self):\n",
        "    b1=self.n*self.batchSize\n",
        "    b2=(self.n+1)*self.batchSize\n",
        "\n",
        "    if self.mode =='FFTnet':\n",
        "      for i in range(self.batchSize):\n",
        "        chunk_start_position = self.n%(self.GT_IR.shape[2]-self.chunkSize)\n",
        "        chunk_number = int(self.n/(self.GT_IR.shape[2]-self.chunkSize))\n",
        "        GT_IR_file = chunk_number%self.GT_IR.shape[1]\n",
        "        GT_file =int(chunk_number/self.GT_IR.shape[1])\n",
        "        GT_position = int((self.chunkSize-1)/2)\n",
        "        if GT_file <self.GT_IR.shape[0]:\n",
        "          if i == 0:\n",
        "            x = self.GT_IR[GT_file,GT_IR_file,chunk_start_position:chunk_start_position+self.chunkSize].view(1,1,-1)\n",
        "            y = self.GT[GT_file,GT_IR_file,chunk_start_position+GT_position].view(1,1)\n",
        "            # print(y)\n",
        "            self.n+=1\n",
        "          else:\n",
        "            x = torch.cat((x,self.GT_IR[GT_file,GT_IR_file,chunk_start_position:chunk_start_position+self.chunkSize].view(1,1,-1)),0 )\n",
        "            y = torch.cat((y,self.GT[GT_file,GT_IR_file,chunk_start_position+GT_position].view(1,1)),0)\n",
        "            self.n+=1\n",
        "         \n",
        "        else:\n",
        "            raise StopIteration\n",
        "      return x,y, 0, 0 #last 2 zeros are placeholders, so the iterator is consistent\n",
        "    if b2<=self.GT_IR.shape[0]:\n",
        "      if self.mode == 'spectrogram':\n",
        "        x = self.GT_IR[b1:b2,:,:,:]\n",
        "        y = self.GT[b1:b2,:,:,:]\n",
        "        self.n+=1\n",
        "        return x,y, 0, 0 #last 2 zeros are placeholders, so the iterator is consistent\n",
        "      elif self.mode == 'waveform':\n",
        "        x = self.GT_IR[b1:b2,:,:]\n",
        "        y = self.GT[b1:b2,:,:]\n",
        "        self.n+=1\n",
        "        return x,y, 0, 0 #last 2 zeros are placeholders, so the iterator is consistent\n",
        "      elif self.mode == 'stft':\n",
        "        x = self.GT_IR[b1:b2,:,:,:]\n",
        "        y = self.GT[b1:b2,:,:,:]\n",
        "        x_phase = self.GT_IR_phase[b1:b2,:,:,:]\n",
        "        y_phase = self.GT_phase[b1:b2,:,:,:]\n",
        "        self.n+=1\n",
        "        return x,y, x_phase, y_phase\n",
        "\n",
        "    else:\n",
        "      raise StopIteration\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x5uZSCEChZn",
        "colab_type": "text"
      },
      "source": [
        "# Custom functions (loss, weight init and RAdam)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V5s2I-7G4ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#init xavier weights\n",
        "def init_weights(m):\n",
        "      if type(m) == nn.Conv1d:\n",
        "          torch.nn.init.xavier_normal_(m.weight)\n",
        "          m.bias.data.fill_(0)\n",
        "      elif type(m) == nn.ConvTranspose1d:\n",
        "          torch.nn.init.xavier_normal_(m.weight)\n",
        "          m.bias.data.fill_(0)\n",
        "\n",
        "#Custom sftf loss function for waveform\n",
        "def stftMAE(y_pred,y_true,n_fft=160):\n",
        "  pred_stft = torch.stft(y_pred.squeeze(1),n_fft,hop_length=n_fft//2, normalized = True)\n",
        "  pred_stft = torch.abs(pred_stft)\n",
        "  true_stft = torch.stft(y_true.squeeze(1),n_fft,hop_length=n_fft//2, normalized = True)\n",
        "  true_stft = torch.abs(true_stft)\n",
        "  mae = F.l1_loss(pred_stft,true_stft)\n",
        "  return mae\n",
        "\n",
        "def stftHuber(y_pred,y_true,n_fft=160):\n",
        "  pred_stft = torch.stft(y_pred.squeeze(1),n_fft,hop_length=n_fft//2, normalized = True)\n",
        "  pred_stft = torch.abs(pred_stft)\n",
        "  true_stft = torch.stft(y_true.squeeze(1),n_fft,hop_length=n_fft//2, normalized = True)\n",
        "  true_stft = torch.abs(true_stft)\n",
        "  mae = F.smooth_l1_loss(pred_stft,true_stft)\n",
        "  return mae\n",
        "  \n",
        "def stftMSE(y_pred,y_true,n_fft=160):\n",
        "  pred_stft = torch.stft(y_pred,n_fft,hop_length=n_fft//2)\n",
        "  true_stft = torch.stft(y_true,n_fft,hop_length=n_fft//2)\n",
        "  mse = F.mse_loss(pred_stft,true_stft)\n",
        "  return mse\n",
        "\n",
        "def magMAE(y_pred,y_true,n_fft=160):\n",
        "  pred_stft = torch.stft(y_pred.squeeze(1),n_fft,hop_length=n_fft//2)\n",
        "  true_stft = torch.stft(y_true.squeeze(1),n_fft,hop_length=n_fft//2)\n",
        "  pred_mag,pred_phase = ta.functional.magphase(pred_stft)\n",
        "  true_mag,true_phase = ta.functional.magphase(true_stft)\n",
        "  mae = F.l1_loss(pred_mag,true_mag)\n",
        "  return mae\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFto61WeY9hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "\n",
        "class RAdam(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "        \n",
        "        self.degenerated_to_sgd = degenerated_to_sgd\n",
        "        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n",
        "            for param in params:\n",
        "                if 'betas' in param and (param['betas'][0] != betas[0] or param['betas'][1] != betas[1]):\n",
        "                    param['buffer'] = [[None, None, None] for _ in range(10)]\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, buffer=[[None, None, None] for _ in range(10)])\n",
        "        super(RAdam, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(RAdam, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                buffered = group['buffer'][int(state['step'] % 10)]\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, step_size = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "\n",
        "                    # more conservative since it's an approximated value\n",
        "                    if N_sma >= 5:\n",
        "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    elif self.degenerated_to_sgd:\n",
        "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        step_size = -1\n",
        "                    buffered[2] = step_size\n",
        "\n",
        "                # more conservative since it's an approximated value\n",
        "                if N_sma >= 5:\n",
        "                    if group['weight_decay'] != 0:\n",
        "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
        "                    p.data.copy_(p_data_fp32)\n",
        "                elif step_size > 0:\n",
        "                    if group['weight_decay'] != 0:\n",
        "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
        "                    p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss\n",
        "\n",
        "class PlainRAdam(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "                    \n",
        "        self.degenerated_to_sgd = degenerated_to_sgd\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "\n",
        "        super(PlainRAdam, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(PlainRAdam, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                beta2_t = beta2 ** state['step']\n",
        "                N_sma_max = 2 / (1 - beta2) - 1\n",
        "                N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "\n",
        "\n",
        "                # more conservative since it's an approximated value\n",
        "                if N_sma >= 5:\n",
        "                    if group['weight_decay'] != 0:\n",
        "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "                    step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
        "                    p.data.copy_(p_data_fp32)\n",
        "                elif self.degenerated_to_sgd:\n",
        "                    if group['weight_decay'] != 0:\n",
        "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "                    step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
        "                    p_data_fp32.add_(-step_size, exp_avg)\n",
        "                    p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjSYlGKfEdeQ",
        "colab_type": "text"
      },
      "source": [
        "# Define neural network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjxi6lvubu3-",
        "colab_type": "text"
      },
      "source": [
        "## FFTnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUQGJEC2b0xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create SE-FFTnet Block\n",
        "        \n",
        "        \n",
        "class FFTNet_block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, hid_channels, layer_id, std_f=0.5):\n",
        "    super(FFTNet_block, self).__init__()\n",
        "    self.layer_id = layer_id\n",
        "    self.dialation = 2**layer_id\n",
        "    self.block_size = 4*(2**(layer_id-1))-1\n",
        "    self.start_idx = [0,0+self.dialation,0+self.block_size+1]\n",
        "    self.receptive_field =  4*self.dialation-1\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.hid_channels = hid_channels\n",
        "    self.conv1_1 = nn.Conv1d(in_channels, hid_channels, 1, stride=1)\n",
        "    self.conv1_2 = nn.Conv1d(in_channels, hid_channels, 1, stride=1)\n",
        "    self.conv1_3 = nn.Conv1d(in_channels, hid_channels, 1, stride=1)\n",
        "    self.conv2 = nn.Conv1d(hid_channels, out_channels, 1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.init_weights(std_f)\n",
        "    self.buffer = None\n",
        "    self.cond_buffer = None\n",
        "    # inference params for linear operations\n",
        "    self.w1_1 = None\n",
        "    self.w1_2 = None\n",
        "    self.w2 = None\n",
        "\n",
        "  def init_weights(self, std_f):\n",
        "    std = np.sqrt(std_f / self.in_channels)\n",
        "    self.conv1_1.weight.data.normal_(mean=0, std=std)\n",
        "    self.conv1_1.bias.data.zero_()\n",
        "    self.conv1_2.weight.data.normal_(mean=0, std=std)\n",
        "    self.conv1_2.bias.data.zero_()\n",
        "    self.conv1_3.weight.data.normal_(mean=0, std=std)\n",
        "    self.conv1_3.bias.data.zero_()\n",
        "\n",
        "  def forward(self, x, cx=None):\n",
        "    T = x.shape[1]\n",
        "    if self.receptive_field == 3:\n",
        "      x1 = x[:, :,0].unsqueeze(2)\n",
        "      x2 = x[:, :,1].unsqueeze(2)\n",
        "      x3 = x[:, :,2].unsqueeze(2)\n",
        "    else:\n",
        "      x1 = x[:, :,self.start_idx[0]:self.start_idx[0] + self.block_size]\n",
        "      x2 = x[:, :,self.start_idx[1]:self.start_idx[1] + self.block_size]\n",
        "      x3 = x[:, :,self.start_idx[2]:self.start_idx[2] + self.block_size]\n",
        "    z1 = self.conv1_1(x1)\n",
        "    z2 = self.conv1_2(x2)\n",
        "    z3 = self.conv1_3(x3)\n",
        "    z = z1 + z2 + z3\n",
        "\n",
        "    out = self.relu(z)\n",
        "    out = self.conv2(out)\n",
        "    out = self.relu(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "class FFTNetModel(nn.Module):\n",
        "  def __init__(self, hid_channels=256, out_channels=1, n_layers=4,\n",
        "    cond_channels=None):\n",
        "    super(FFTNetModel, self).__init__()\n",
        "    self.cond_channels = cond_channels\n",
        "    self.hid_channels = hid_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.n_layers = n_layers\n",
        "    self.receptive_field = 4*(2**(n_layers-1))-1\n",
        "\n",
        "    self.layers = []\n",
        "    for idx in reversed(range(self.n_layers)):\n",
        "      layer_id = idx\n",
        "      if idx == n_layers-1:\n",
        "       layer = FFTNet_block(1, hid_channels, hid_channels, layer_id=layer_id)\n",
        "      else:\n",
        "       layer = FFTNet_block(hid_channels, hid_channels, hid_channels, layer_id=layer_id)\n",
        "      \n",
        "      self.layers.append(layer)\n",
        "    self.layers = nn.ModuleList(self.layers)\n",
        "    self.fc = nn.Linear(hid_channels, out_channels)\n",
        "    print('Receptive Field =  ',self.receptive_field, ' samples')\n",
        "  def forward(self, x, cx=None):\n",
        "    # FFTNet modules\n",
        "    # out = x.view(1,1,-1)\n",
        "    out = x\n",
        "    for idx, layer in enumerate(self.layers):\n",
        "      out = layer(out)\n",
        "    out = out.transpose(1, 2)\n",
        "    out = self.fc(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHx5WUGzPs98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def applyToFile(net,x):\n",
        "  block_size = net.receptive_field\n",
        "  start = 0\n",
        "  finish = start + block_size\n",
        "  input_lenght = (x.shape[2])\n",
        "  print(input_lenght)\n",
        "  output = np.zeros((input_lenght,1))\n",
        "  while finish < input_lenght:\n",
        "    chunk = x[:,:,start:finish]\n",
        "    temp = net(chunk.cuda())\n",
        "    out = temp.cpu().detach().numpy()\n",
        "    output[start] = out\n",
        "    start += 1\n",
        "    finish = start + block_size \n",
        "  \n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbXVx_PAFFha",
        "colab_type": "text"
      },
      "source": [
        "# Pipeline functions\n",
        "Useful so we can make a loop where different hyper parameters are tested\n",
        "\n",
        "Hyperparameters we want to test:\n",
        "\n",
        "* Data type: waveform(Conv1D) or spectrogram(Conv2D) (CNN='1d' or CNN='2d')\n",
        "* Input size/no of samples (chunk_size)\n",
        "* Loss function (MAE, MSE, Huber, cosh. Measured on waveform/stft real+imaginary/stft mag/stft mag+phase)\n",
        "* Regularization\n",
        "* Optimizer (always Adam? Try AdamW (weight decay))\n",
        "* Optimizer learning rate (optim.lr_scheduler)\n",
        "* Batch size ?\n",
        "* Epochs ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b68ZnccGUDtl",
        "colab_type": "text"
      },
      "source": [
        "## Data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p4LRoJgLVKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DataLoader\n",
        "def PipelineData(SAMPLE_RATE=16000, CNN='2d',\n",
        "                       batch_size=64, chunk_size=None,\n",
        "                       train_GT_range=[0,200],\n",
        "                       train_IR_range=[0,24], train_N_range=[0,1],\n",
        "                       train_sequence_length_GT=16000*2,\n",
        "                       train_sequence_length_IR=16000*1,\n",
        "                       test_GT_range=[4030,4050],\n",
        "                       test_IR_range=[30,36], test_N_range=[0,1],\n",
        "                       test_sequence_length_GT=16000*2,\n",
        "                       test_sequence_length_IR=8000*1,\n",
        "                       matrix_ops=True):\n",
        "  \n",
        "  #Data preprocessing:\n",
        "  #total GT files: 4162\n",
        "  #total IR files: 36\n",
        "  trainLoader=DataLoader(GT_range=train_GT_range,\n",
        "                         IR_range=train_IR_range,\n",
        "                         N_range=train_N_range,\n",
        "                         sequence_length_GT=train_sequence_length_GT,\n",
        "                         sequence_length_IR=train_sequence_length_IR)\n",
        "\n",
        "  #trainLoader.printFilenames('GT')\n",
        "  #trainLoader.printFilenames('IR')\n",
        "\n",
        "  trainLoader.cropAndPadIR(matrix_ops=matrix_ops)\n",
        "  trainLoader.cropAndPadGT(matrix_ops=matrix_ops)\n",
        "  trainLoader.add_reverb(matrix_ops=matrix_ops)\n",
        "  trainLoader.normalize()\n",
        "  trainLoader.cpu()\n",
        "  if CNN=='2d':\n",
        "    trainLoader.stft()\n",
        "  \n",
        "  \n",
        "  testLoader=DataLoader(GT_range=test_GT_range,\n",
        "                         IR_range=test_IR_range,\n",
        "                         N_range=test_N_range,\n",
        "                         sequence_length_GT=test_sequence_length_GT,\n",
        "                         sequence_length_IR=test_sequence_length_IR)\n",
        "\n",
        "\n",
        "  #testLoader.printFilenames('GT')\n",
        "  #testLoader.printFilenames('IR')\n",
        "  \n",
        "  testLoader.cropAndPadIR(matrix_ops=matrix_ops)\n",
        "  testLoader.cropAndPadGT(matrix_ops=matrix_ops)\n",
        "  testLoader.add_reverb(matrix_ops=matrix_ops)\n",
        "  testLoader.normalize()\n",
        "  testLoader.cpu()\n",
        "  if CNN=='2d':\n",
        "    testLoader.stft()\n",
        "  \n",
        "  #Iterator:\n",
        "  if CNN=='2d':\n",
        "    trainIterator=Iterator(trainLoader,mode='stft')\n",
        "    testIterator=Iterator(testLoader,mode='stft')\n",
        "  elif CNN=='FFTnet':\n",
        "    trainIterator=Iterator(trainLoader,mode='FFTnet')\n",
        "    testIterator=Iterator(testLoader,mode='FFTnet')    \n",
        "  else:\n",
        "    trainIterator=Iterator(trainLoader,mode='waveform')\n",
        "    testIterator=Iterator(testLoader,mode='waveform')\n",
        "\n",
        "  trainIterator.setBatchSize(batch_size)\n",
        "  testIterator.setBatchSize(batch_size)\n",
        "\n",
        "  if chunk_size:\n",
        "    trainIterator.setChunkSize(chunk_size)\n",
        "    testIterator.setChunkSize(chunk_size)\n",
        "    trainIterator.chunkify()\n",
        "    testIterator.chunkify()\n",
        "  \n",
        "  print(f\"Shape of train.GT: {trainIterator.GT.shape}\")\n",
        "  print(f\"Shape of test.GT: {testIterator.GT.shape}\")\n",
        "  print(f\"Shape of train.GT_IR: {trainIterator.GT_IR.shape}\")\n",
        "  print(f\"Shape of test.GT_IR: {testIterator.GT_IR.shape}\")\n",
        "\n",
        "  return trainIterator, testIterator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QUh1f7JUHMS",
        "colab_type": "text"
      },
      "source": [
        "## Model pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc7pGrwKFHsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def PipelineModel(CNN='2d', kernel_size=11, optim='Adam',learning_rate=None,loss='Huber',use_cuda=True, layers = 10):\n",
        "\n",
        "  #Define the model:\n",
        "  assert CNN in ('2d', 'Baseline', 'Baseline_BN','FFTnet')\n",
        "  if CNN=='2d':\n",
        "    net = CNN2d(kernel_size)\n",
        "    net.apply(init_weights)\n",
        "  elif CNN=='Baseline_BN':\n",
        "    net = Baseline_BN(kernel_size)\n",
        "    net.apply(init_weights)\n",
        "  elif CNN=='Baseline':\n",
        "    net = Baseline(kernel_size)\n",
        "    net.apply(init_weights)\n",
        "  elif CNN == 'FFTnet':\n",
        "    net = FFTNetModel(n_layers=layers)\n",
        "  \n",
        "\n",
        "  if use_cuda:\n",
        "    net = net.cuda()\n",
        "  #Optimizer:\n",
        "  if optim=='Adam':\n",
        "    if learning_rate==None:\n",
        "      learning_rate=0.001\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "  elif optim=='AdamW':\n",
        "    if learning_rate==None:\n",
        "      learning_rate=0.001\n",
        "    optimizer = torch.optim.AdamW(net.parameters(), lr=learning_rate)\n",
        "  elif optim=='RAdam':\n",
        "    if learning_rate==None:\n",
        "      learning_rate=0.001\n",
        "    optimizer = RAdam(net.parameters(), lr=learning_rate)\n",
        "  #Loss:\n",
        "  if loss=='L2':\n",
        "    loss_function = nn.MSELoss()\n",
        "  elif loss=='L1':\n",
        "    loss_function = nn.L1Loss()\n",
        "  elif loss=='Huber':\n",
        "    loss_function = nn.SmoothL1Loss()\n",
        "  elif loss=='stftMAE':\n",
        "    loss_function = stftMAE\n",
        "  elif loss=='stftHuber':\n",
        "    loss_function = stftHuber\n",
        "  elif loss=='magMAE':\n",
        "    loss_function = magMAE\n",
        "  else:\n",
        "    print(\"Invalid loss function\")\n",
        "\n",
        "  return net, optimizer, loss_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV-iPPlzUJt2",
        "colab_type": "text"
      },
      "source": [
        "## Fitting pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzmVSIjeSX4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(state, old_loss, loss, is_best, filename='/content/drive/My Drive/reverberation/Models/test.pth.tar'):\n",
        "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
        "    if is_best:\n",
        "        print (f\"=> Saving a new best loss improved from {old_loss} to {loss}\")\n",
        "        torch.save(state, filename)  # save checkpoint\n",
        "    else:\n",
        "        print (\"=> Validation Accuracy did not improve\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb4HpvKkUCGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO DO: \n",
        "## Return results\n",
        "## Iterators can return 2 or 4 arguments\n",
        "def PipelineFit(net, optimizer, loss_function,\n",
        "                trainIterator, testIterator,\n",
        "                num_epochs, save_name, \n",
        "                scheduler_step_size=1,\n",
        "                scheduler_gamma=0.9,\n",
        "                plotting=False, return_results=True, \n",
        "                use_cuda=True):\n",
        "  print(\"Training network...\")\n",
        "  tmp_img = \"tmp_ae_out.png\"\n",
        "  train_loss = []\n",
        "  valid_loss = []\n",
        "  Scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    batch_loss = []\n",
        "    net.train()\n",
        "    # Go through each batch in the training dataset using the loader\n",
        "    # Note that y is not necessarily known as it is here\n",
        "    #for ir in range(27):\n",
        "    trainIter=iter(trainIterator)\n",
        "    #count=0\n",
        "    for x,target,x_phase,target_phase in trainIter:\n",
        "      optimizer.zero_grad()\n",
        "      x = Variable(x,requires_grad=True)\n",
        "      if use_cuda:\n",
        "        x = x.cuda()\n",
        "        target=target.cuda()\n",
        "      output = net(x)\n",
        "      loss = loss_function(target.squeeze(), output.squeeze())\n",
        "      batch_loss.append(loss.item())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    train_loss.append(np.mean(batch_loss))\n",
        "\n",
        "    # Evaluate, do not propagate gradients\n",
        "    with torch.no_grad():\n",
        "      batch_loss = []\n",
        "      net.eval()\n",
        "      testIter=iter(testIterator)\n",
        "      for x,target,x_phase,target_phase in testIter:\n",
        "        x = Variable(x)\n",
        "        if use_cuda:\n",
        "          x = x.cuda()\n",
        "          target = target.cuda()\n",
        "\n",
        "        output = net(x)\n",
        "        loss = loss_function(target.squeeze(), output.squeeze())\n",
        "        #Ferdi's stuff:\n",
        "        batch_loss.append(loss.item())\n",
        "      valid_loss.append(np.mean(batch_loss))\n",
        "    \n",
        "    Scheduler.step()\n",
        "\n",
        "    if epoch+1 == 1:\n",
        "      best_loss = valid_loss[epoch]\n",
        "\n",
        "    # Get bool not ByteTensors\n",
        "    print(valid_loss[epoch])\n",
        "    print(best_loss)\n",
        "    is_best = bool(valid_loss[epoch] < best_loss)\n",
        "    if is_best:\n",
        "      old_loss = best_loss\n",
        "    else:\n",
        "      old_loss = 0\n",
        "    # Get greater Tensor to keep track best acc\n",
        "    best_loss = min(valid_loss[epoch], best_loss)\n",
        "    # Save checkpoint if is a new best\n",
        "\n",
        "    save_checkpoint({\n",
        "        'epoch': epoch + 1,\n",
        "        'state_dict':  net.state_dict(),\n",
        "        'best_loss': best_loss\n",
        "    }, old_loss, best_loss, is_best, filename=str(save_name)+'.pth.tar')\n",
        "\n",
        "    if epoch == 0:\n",
        "      continue\n",
        "    \n",
        "    if plotting:\n",
        "\n",
        "      # -- Plotting --\n",
        "      f, ax1 = plt.subplots(figsize=(8,8))\n",
        "    \n",
        "      # Loss\n",
        "      #ax = axarr[0]\n",
        "      ax1.set_title(\"Loss\")\n",
        "      ax1.set_xlabel('Epoch')\n",
        "      ax1.set_ylabel('Loss')\n",
        "      #ax2.set_title(\"Validation error\")\n",
        "      #ax2.set_xlabel('Epoch')\n",
        "      #ax2.set_ylabel('Error')\n",
        "\n",
        "\n",
        "      ax1.plot(np.arange(epoch+1), train_loss, color=\"blue\", linestyle=\"-.\")\n",
        "      ax1.plot(np.arange(epoch+1), valid_loss, color=\"red\", linestyle=\"-.\")\n",
        "      ax1.legend(['Training','Validation'])\n",
        "      plt.tight_layout()\n",
        "      plt.savefig(tmp_img)\n",
        "      plt.close(f)\n",
        "      display(Image(filename=tmp_img))\n",
        "      clear_output(wait=True)\n",
        "\n",
        "      os.remove(tmp_img)\n",
        "\n",
        "  if return_results:\n",
        "    return train_loss,valid_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3ayxhz0Kw2K",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation pipeline - ONLY for waveform so far"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a7nxW9uKxPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluationMetrics(net,testIterator,mode,cuda=True,cutoff=100):\n",
        "  assert mode in ('waveform','stft')\n",
        "  \n",
        "  ### ONLY waveform IMPLEMENTATION ###\n",
        "\n",
        "  SAMPLE_RATE=16000\n",
        "  net.eval()\n",
        "\n",
        "  #Collect inputs, outputs and targets\n",
        "  lossPESQ = []\n",
        "  lossSTOI = []\n",
        "  dummyPESQ = []\n",
        "  dummySTOI = []\n",
        "  Iterator = iter(testIterator)\n",
        "  count=0\n",
        "  for x,target,x_phase,target_phase in Iterator:\n",
        "    if cuda:\n",
        "      x=x.cuda()\n",
        "    y=net(x)\n",
        "    y=y.view(-1).cpu().detach().numpy()\n",
        "    #outputs=np.append(outputs,y)\n",
        "    \n",
        "    x=x.view(-1).cpu().detach().numpy()\n",
        "    #inputs=np.append(inputs,x)\n",
        "\n",
        "    target=target.view(-1).cpu().detach().numpy()\n",
        "    #targets=np.append(targets,target)\n",
        "    #metrics:\n",
        "    lossPESQ.append(pesq(SAMPLE_RATE, target, y, 'wb'))\n",
        "    dummyPESQ.append(pesq(SAMPLE_RATE, target, x, 'wb'))\n",
        "    # lossSTOI.append(stoi(target, y, SAMPLE_RATE, extended=False))\n",
        "    # dummySTOI.append(stoi(target, x, SAMPLE_RATE, extended=False))\n",
        "\n",
        "    count+=1\n",
        "    if count==cutoff:\n",
        "      break\n",
        "\n",
        "  print(count)\n",
        "  print('The results below is based on the 64 reconstructed sound files')\n",
        "  #print('Mean loss of MSE: ' + str(lossMSE))\n",
        "  #print('Variance loss of MSE: '+ str(np.var(lossMSE)))\n",
        "  print('Mean loss of PESQ: ' + str(np.mean(lossPESQ)))\n",
        "  print('Variance loss of PESQ: '+ str(np.var(lossPESQ)))\n",
        "  print('Mean loss of STOI: ' + str(np.mean(lossSTOI)))\n",
        "  print('Variance loss of STOI: '+ str(np.var(lossSTOI)))\n",
        "\n",
        "\n",
        "  print('The results below is based on the 64 noisy sound files')\n",
        "  #print('Mean loss of MSE: ' + str(dummyMSE))\n",
        "  #print('Variance loss of MSE: '+ str(np.var(lossMSE)))\n",
        "  print('Mean loss of PESQ: ' + str(np.mean(dummyPESQ)))\n",
        "  print('Variance loss of PESQ: '+ str(np.var(dummyPESQ)))\n",
        "  print('Mean loss of STOI: ' + str(np.mean(dummySTOI)))\n",
        "  print('Variance loss of STOI: '+ str(np.var(dummySTOI)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSfifLXZNTeZ",
        "colab_type": "text"
      },
      "source": [
        "# Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxgVch_thSDZ",
        "colab_type": "text"
      },
      "source": [
        "## Model step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y3xdrp7uRhP",
        "colab_type": "code",
        "outputId": "36770c9f-f5a5-4c07-e412-8055f0937e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net,optimizer,loss_function=PipelineModel(CNN='FFTnet',kernel_size=10,learning_rate=0.001, optim='Adam',loss='L1',use_cuda=cuda, layers = 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Receptive Field =   2047  samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxokbRyChT2y",
        "colab_type": "text"
      },
      "source": [
        "## Data step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPs3gQZ1QfQo",
        "colab_type": "code",
        "outputId": "05592de8-225b-4bbb-fad4-e19594a13d7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        " ## Get training and test iterators:\n",
        "trainIterator, testIterator=PipelineData(SAMPLE_RATE=16000, CNN='FFTnet',\n",
        "                       train_GT_range=[0,30],\n",
        "                       train_IR_range=[0,4],\n",
        "                       test_GT_range=[31,40],\n",
        "                       test_IR_range=[0,4],\n",
        "                       batch_size=128, chunk_size=net.receptive_field,\n",
        "                       matrix_ops=True) #Set matrix_ops to False, if cuda does not have enough memory"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 30 ground truth files in data set\n",
            "Found 4 impulse response files in data set\n",
            "Found 1 noise files in data set\n",
            "\n",
            "Running GPU.\n",
            "GT\n",
            "Processing file 1 of 30...\n",
            "IR\n",
            "Processing file 1 of 4...\n",
            "N\n",
            "Processing file 1 of 1...\n",
            "Found 9 ground truth files in data set\n",
            "Found 4 impulse response files in data set\n",
            "Found 1 noise files in data set\n",
            "\n",
            "Running GPU.\n",
            "GT\n",
            "Processing file 1 of 9...\n",
            "IR\n",
            "Processing file 1 of 4...\n",
            "N\n",
            "Processing file 1 of 1...\n",
            "Shape of train.GT: torch.Size([30, 4, 32000])\n",
            "Shape of test.GT: torch.Size([9, 4, 32000])\n",
            "Shape of train.GT_IR: torch.Size([30, 4, 32000])\n",
            "Shape of test.GT_IR: torch.Size([9, 4, 32000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdNVt613FUri",
        "colab_type": "code",
        "outputId": "8ce42cb3-a1d0-4098-e480-a2df4fdbf2d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cp = torch.load('/content/drive/My Drive/reverberation/Models/SEFFT_net_short.pth.tar')\n",
        "\n",
        "net.load_state_dict(cp)\n",
        "net.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIOaUxRFh7lB",
        "colab_type": "code",
        "outputId": "97719d64-f8ca-4a4a-c784-729b616b5818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        " ## See how many parameters are in the model (Optional)\n",
        "pytorch_total_params = sum(p.numel() for p in net.parameters())\n",
        "pytorch_trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Total parameters in the model: {pytorch_total_params}\")\n",
        "print(f\"Total trainable parameters in the model: {pytorch_trainable_params}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-473b6c53e653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpytorch_total_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpytorch_trainable_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total parameters in the model: {pytorch_total_params}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total trainable parameters in the model: {pytorch_trainable_params}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fvf5ZJfhdFG",
        "colab_type": "text"
      },
      "source": [
        "## Training step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0JRC-HFXTu0o",
        "outputId": "f09418b7-0927-470d-81b1-9b8377cbef3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " ## Perform the training loop:\n",
        "train_loss,valid_loss=PipelineFit(net,optimizer,loss_function,\n",
        "                                  trainIterator,testIterator,\n",
        "                                  num_epochs=30,\n",
        "                                  save_name=\"FFTNet\",\n",
        "                                  scheduler_step_size=1,\n",
        "                                  scheduler_gamma=0.9,\n",
        "                                  plotting=True,return_results=True,use_cuda=cuda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training network...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhiWbsEkkOH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " torch.save(net.state_dict(), '/content/drive/My Drive/reverberation/Models/SEFFT_net_short.pth.tar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOpdhgFOTrF0",
        "colab_type": "code",
        "outputId": "33caf372-3d6f-4ebd-9478-e2b550baf4d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# net.load_state_dict(torch.load('/content/drive/My Drive/reverberation/Models/1d_2000_BN_DO.p'))\n",
        "net.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FFTNetModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): FFTNet_block(\n",
              "      (conv1_1): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_2): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_3): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): FFTNet_block(\n",
              "      (conv1_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): FFTNet_block(\n",
              "      (conv1_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): FFTNet_block(\n",
              "      (conv1_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): FFTNet_block(\n",
              "      (conv1_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): FFTNet_block(\n",
              "      (conv1_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): FFTNet_block(\n",
              "      (conv1_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): FFTNet_block(\n",
              "      (conv1_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): FFTNet_block(\n",
              "      (conv1_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (9): FFTNet_block(\n",
              "      (conv1_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv1_3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdyIMWg___At",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXRqxu4dl6nc",
        "colab_type": "code",
        "outputId": "59394755-e7cf-4b7e-8788-4ca75b414867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "SAMPLE_RATE = 16000\n",
        "input_file = testIterator.GT_IR[0,0,:]\n",
        "GT = testIterator.GT[0,0,:]\n",
        "result = applyToFile(net,input_file.view(1,1,-1))\n",
        "target=GT.view(-1).cpu().detach().numpy()\n",
        "result = np.reshape(result,result.shape[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDHL2YwCmjyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st = stoi(target, result, 16000, extended=False)\n",
        "print(st)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNcS3jg5pk-U",
        "colab_type": "code",
        "outputId": "dded5706-2ee2-462a-c5fe-a563c7536132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "psq = pesq(SAMPLE_RATE, target, result, 'wb')\n",
        "print(psq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0542824268341064\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}